from calibre.web.feeds.news import BasicNewsRecipe, classes
from calibre.ptempfile import PersistentTemporaryFile

class STHKRecipe(BasicNewsRecipe):
    title = '星島日報 (香港)'
    __author__ = 'unkn0wn'
    description = 'The Sing Tao Daily is among Hong Kong's oldest Chinese language newspapers. (https://std.stheadline.com/)'
    category = 'Chinese, News, Hong Kong'
    masthead_url = 'https://std.stheadline.com/dist/images/logo-v2@2x.png'
    no_stylesheets = True
    remove_javascript = True
    ignore_duplicate_articles = {'title'}
    resolve_internal_links  = True
    remove_empty_feeds = True

    extra_css = '''
        img {display:block; margin:0 auto;}
        .date { font-size:small; }
        .caption-text, .media-library-item__attributes { font-size:small; text-align:center; }
    '''

    keep_only_tags = [
        dict(name='article', attrs={'class':'content'})
    ]
    remove_tags = [
        dict(name=['video', 'svg', 'button']), 
        dict(attrs={'id':'articleShareIcons'}),
        classes('in-article-banner stick-box-gray article-pagination comments')
    ]

    articles_are_obfuscated = True

    def get_obfuscated_article(self, url):
        br = self.get_browser()
        try:
            br.open(url)
        except Exception as e:
            url = e.hdrs.get('location')
        soup = self.index_to_soup(url)
        link = soup.find('a', href=True)
        skip_sections =[ # add sections you want to skip
            '/video/', '/videos/', '/media/', 'podcast'
        ]
        if any(x in link['href'] for x in skip_sections):
            self.log('Aborting Article ', link['href'])
            self.abort_article('skipping video links')

        self.log('Downloading ', link['href'])
        html = br.open(link['href']).read()
        pt = PersistentTemporaryFile('.html')
        pt.write(html)
        pt.close()
        return pt.name

    feeds = []

    sections = [
        'daily', 'realtime', 'education', 'property', 'racing', 'supplement', 'kol'
    ]

    for sec in sections:
        a = 'https://news.google.com/rss/search?q=when:27h+allinurl:https%3A%2F%2Fstd.stheadline.com{}&hl=zh-HK&gl=HK&ceid=HK:zh'
        feeds.append((sec.capitalize(), a.format('%2F' + sec + '%2F')))
    feeds.append(('Others', a.format('')))

    def populate_article_metadata(self, article, soup, first):
        article.title = article.title.replace(' - 星島頭條', '')

    def preprocess_raw_html(self, raw, *a):
        return raw.replace('<p></p>', '')
